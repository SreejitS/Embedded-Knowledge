#### Preemptive, priority-based scheduling
- We will focus on extending RTOS with a preemptive, priority-based scheduler, which can be mathematically proven to meet real-time deadlines under certain conditions. 

##### What is Real-Time?
- Any computation that was performed was considered equally useful, and you cared only whether the computation was correct, but not whether it was performed within a given time. "Real-Time" adds the timeliness requirement to the computations.
- Specifically, a computation that is performed too late (or too early for that matter) is considered less useful and even harmful as an outright wrong computation.
- In the so called "hard real-time systems", a computation is useful from the triggering event up to the deadline. After the deadline, the usefulness of the computation becomes "negative infinity", which means that the computation is worse that useless (for that its usefulness would be merely zero). A missed deadline represents a system failure. For example, deploying an air-bag too late is not just useless--it is disastrous.
- There are also "soft real-time systems", where timeliness is also important, but the deadline is not as firm. For example, a text message is expected to be delivered somewhat timely, say within 20 seconds. But it is still useful much longer, although its usefulness diminishes with time.
- Most real-time systems operate in a periodic fashion, meaning that the triggering events and the deadlines repeat with a certain period.

##### Issue with round robin
- Setup explanation:
	- ISR i.e. the `SysTick`  interrupt is set up to fire every 1ms. T1 thread has a period of 2ms, and the runs for 1.2ms. T2 thread has a period of 54ms and has runs for 3.6ms.
- We can see that if we use the round robin scheduler, then T1 threads misses it's 2ms deadline in a situation where T1 and T2 are both in ready state. T1 is pre-empted when it's allocated time slice is over and then T2 is scheduled.
- When both of the threads are not ready, then the idle thread is scheduled
![[round-robin.JPG]]

##### Priority based scheduling
- Here T1 is set to have more priority than T2. So, when T1 is executing, and sees that T2 is also ready for execution, the scheduler chooses T1 to run because of the priority.
- T2 thread is scheduled only after T1 voluntarily BLOCKS in the `OS_delay()` function. But as soon as T1 is unblocked again, the scheduler immediately switches back to T1, because it has higher PRIORITY than T2.
- Interestingly, notice that even though T2 is significantly delayed by constant interruptions from T1, it too eventually completes and blocks way before its deadline of 54 milliseconds. This means that the priority-based scheduler executes T1 AND T2 in such a way that they BOTH meet their hard real-time deadlines.
![[priority-vs-round-robin.JPG]]

##### Priority Based Static Scheduling with Static Priority
- The previous scheduler was round-robin. This scheduler was designed for timesharing systems, where the most important goal was to share the CPU FAIRLY among all threads. Therefore, the scheduler takes the CPU away from threads after it exhausts its time slice.
- But this is NOT what you want in a hard-real time system. For this you need a different scheduler, which somehow KNOWS about the importance of the threads, so that it can execute a more important thread before executing a less-important thread.
- So, now in the scheduler code, the next task which is set as ready to run is the one with the highest priority. The scheduler still runs periodically.

##### Changes in Scheduler Code
- Instead of setting the next thread to the next available thread, it is set to the thread with the highest priority

##### Setting the priorities of the thread (RMA)
- This simple static priority-based scheduler that you've just seen can be mathematically proven to meet all hard-real-time deadlines for all threads under certain conditions. This analysis is called "Rate-Monotonic Analysis" (RMA) or "Rate-Monotonic Scheduling" (RMS)
	- First, always assign thread priorities monotonically, meaning that threads with higher rates must run at higher priorities than threads with lower rates.
	- Second, you need to know the CPU utilization of each thread, which you calculate as the ratio between the measured execution time Cn to the period Tn.
	- And third, you need to calculate the total CPU utilization as the sum of all individual CPU utilization factors. If this total utilization is below the theoretical bound(), all threads in the set are guaranteed to meet their deadlines.
	- The utilization bound U(n) depends on the number of threads n. For the large number of threads, U(n) approaches natural logarithm of 2, which is just under 0.7. So, in practice, if you stay below 70% of the CPU utilization, your set of threads will be schedulable, meaning that they will all meet their deadlines.
	- *In this example, the CPU utilizations are 1.2ms/2ms for T1 plus 3.6ms/54ms for T2. The total CPU utilization is thus 0.666, which is below the theoretical bound.*
	-  Basic RMA assumes periodic threads that execute in constant time. But the method can be extended to aperiodic threads with variable execution time. In that case you need to consider the worst-case, that is the shortest time between the thread activations and the longest execution time.
	- Typically in practice typically only a few highest-priority threads have hard-real-time deadlines, while other threads have only soft-real-time requirements. In that case, you use RMA for the hard-real-time threads and prioritize all soft-real-time threads lower.

#### Conclusion
- The beauty of preemptive priority-based scheduling is that a high-priority thread can always immediately preempt all lower-priority threads, so a high-priority thread is insensitive to changes in execution time or period of lower-priority threads. In other words, the preemptive, priority-based scheduler decouples threads in the time domain.
- For all these reasons, the preemptive, priority-based scheduler became the norm and is supported in most Real-Time Operating Systems to this day.
- [[7. RTOS Part-6 Synchronization and communication among concurrent threads|Next]] , we will advance by another decade from the 1970's to the 1980's, when the commercial RTOS went mainstream, and when inter-thread synchronization and communication mechanisms have been added.
